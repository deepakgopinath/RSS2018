Dec 6th 2017:

1. Revisit the formulation and test for conceptual accuracy. 
	Read about Fisher information more. Read about Miller et al.s work. Look into what kind of simulation results they presented. Can EID of a control mode characterize the "disambiguation" capability of the system, indeed. What does "sensitivity" of entropy to u_h signify. When computing numerical Hessians, the uh vector is perturbed mildly along different dimensions. But in reality if it is a 1D interface, those perturbed u_h are not defined. Does this mean that Fisher information is not defined properly at that point. 


2. Test Numerical Fisher and try out different parameters settings etc. Why is the output in many cases not close to intuition. If it is not it is useless. Why does it deviate quite a bit from the symbolic results when simple forms of confidence functions are used. 
	a. Use finite difference methods - DONE
	b. Use automatic differentiation and quantify the differences - DONE Numerical is fine. For simple functions very close to each other. 
	c. Try out dft based approach and simulate for entire workspace - DONE. Compared to conf and noisy bayes, dft is cpautring the intuition the closest. 
	d: try out more goal configurations. - Sanity checks were performed for "known goal configurations" and results were intuitive. 
	e. Try out E-optimality instead of D-optimality - MAYBE?
	f. Peruse the actual Fisher information values - Gotta do this?
 3. Implement Dk algorithm in MATLAB for comparative purposes. Fisher information based ideas should be at least as good as the heuristic approach in their practical usage. 

4. Should entropy be replaced by Dk. The virtual sensor measures "D_k". OR a combination of entropy and Dk?

5. Extend the NumFisher formulation into Python. Use full 6D. This should be straight forward. The "simulation code" is already in place. 
	USe C++ for speed? Probably? 
	Look into autodiff libraries in C++. Can tensorflow be used for just the autodiff operation - NOT NEEDED. Stick with 
	Either use numdifftools in python. Or implement the Matlab code 

What kind of mathematical guarantees does this have?

Simulation results? We can compare the different inference engines. But that is now helpful for evaluting th disambiguation mteric?
The other thought would be to evaluate how intuitive the algorithm is. But this could be evaluated only if we test on a different set of goal configurations

Compare other metrics? 

Pure Entropy, Heuristic and Fisher? 
Todd' paper considered a 1D scenario. 2D scenario. Showed how the "trajectory evolved". How the EID evolved. 

ReadMiller's TRO

Simulation based results:

Different goal configurations: 
Robot moving towards the goal in the disambiguating mode. 
	Details: From any starting point the robot will starting moving towards a specifeid goal. 
	At every time step the probabilities will get updated and the disambiguated mode will be computed. 
		Should there be blending? Or can that be inferred from the rise in confidence associated with the goal? The human might control the robot in different ways when there is blending or not. 
	Continue motion in the disambiguated mode. And so on and so forth. For simulation purposes we CAN do it at every timestep. But for the real robot, we might have to do some metamodeling (GP) type techniques so that we "interpolate" between known positions. 
	We can do this for a variety of metrics? 
		Disamb: ENT, FI, DK, FRAC_POT? - DONe
		Intent: CONF, DFT, BAYES? - DONE
		Current Input Features: DIST, DIRECTEDNESS, ROT AGREEMENT (ONLY IN rotation space) - CAN BE DONE. PASS AN ARGUMENT WHICH SELECTIVELY ADD FEATURES TO THE INFERENCE ENGINE!
		Space of Simulations: R2, SE2, R3, SE3. (Visualizarion for SE3 might be tricky). attach a frame to the body and have it rotate. 
		Interface mappings: 1D, 2D etc. - DONE

A. MAKE SURE THE "RANGES OF WORKSPACE" ARE SIMILAR TO A REGULAR ROBOT WORKSPACE - DONE
B. MAKE SURE THAT THE "SIMULATED UH IS ALSO WITHIN THE RANGE" - DONE
	Determine direction towards the random gaol in the mode. Then scale it with a magnitude that is appropriate  - DONE
C. IS THE SIMULATED HUMAN ALWAYS GOING TO PRODUCE MAXIMUM UH VELOCITY. SHOULD THERE BE SIMULATION FOR A TIMID HUMAN AND AN AGGRESSIVE HUMAN? SAMPLE FROM A TIMID/ AGGRESSIVE DISTRIBUTION - DECIDED AGAINST. DONE. 

Code to write: 
	1. Need to setup the simulation pipeline. Create different folder for each one of the space of simulations - dONE
	2. Need Rotation simulation. Should be very easy for 2D. For 3D there is some code that can be used - DONE
	3. COde to represent the robot properly (especially in the rotation case. Attach a frame to the robot and the goals to denote the current position and orientation and the goal position and orientations - DONE
	4. Need Dk implemented in MATLAB for comparison. Port from python to MATLAB. Should be easy. But will take some time - DONE
	5. Maybe have a compute_projections separate from compute entropy? Coz, projections is always needed for any type of disamb - DONE



TODO:

1. Implement Dk in MATLAB - DONE
2. Bayesian Inference for different spaces? Tuning the likelihood? DFT for SE3. Reimplent stuff from python. 
	R2 - YES,
	R3 - YES,
	SE2 - YES,
	SE3 - TODO - AS angles between translational vectors and angles between the rotational axis vectors. 
3. Don't change anything about the "simulated" human - DONE, MAYBE ADDED SOME NOIsE TO UH
4. Turn each simulation script into a function that would return all necessary data? Alpha's, mode switches, pg, entropy, FI, num goals, cm - TODO IMporTANT. 


 

ISSUES WITH SE6. NumHessian not working. FIXED. The threshold for curr_input in dft should be lower

1. Implement end condition. Avoid chatter. TODO
	End condition check, to see if it reached goal
	Chatter can happen away from the goal as when, it gets stuck in one of the dimensions and the mode never switches 

2. Implment Dk - Can be done fairly starightforward - DONE
3. Implement Bayes ideas for SE3/SE2 - DONE
4. Fix curr_input rotation component in SE2. The contribution from the rotation seems like a binary contribution. DONE
5. Baseline using Biggest potential mode. DONE

Try implementing C*? 
	Action space - possible max velo motions in current mode. and mode switch dependent on interface. Some interfaces can only do cyclical. 
	Needs discretization of space. What does this mean in SE6?
Concrete Ideas:



Dec 25th 2017:

1. Setup data analysis pipeline - Identify what all analysis I want to do and write scripts that would do it on the simulated data. 
	1. When does alpha kick in? _ INTIAIL ALPHA - DONE
	2. What percentage of time alpha is above - DONE
	3. Does it reach goal or not? - DOES IT GET STUCK AT SOME OTHER PLACE?/ in terms of distance?
	4. Compleition time. If reached goal, when does it reach goal?
	5. How much time does the inference actually identifies the true goal? - DONE
	6. What times are the inferences? 


2. Turn each simulation script into a function that would return all necessary data? Alpha's, mode switches, pg, entropy, FI, num goals, cm - DONE



THoughts:

1. FRactional potential based idea is the human being efficient with mode switches - DONE 
2. Use disambiguating scheme in the beginning part of a trial. Once the intent is clarified switch to fractional potential scheme. 
%initial will help the robot. The robot will help the use - MAYBE. Discussion material. 


1. Fix max fractional potential for SE3. How to compute remaining potential in each dimension DONE
   In terms of rpy angles with respect to R to get to G. 
   In terms of alignment of the angle-axis the current rotation axis and original axis - dONE 


TODO For MICO SIMULATON:

1. Implement numerical differentiation in C++ ? Or learn how to use numdifftools. 
2. Set up the pipeline to trigger the simulation properly. 


DEc 31 2017:

1. Understanding statistical testing. Differences between multiple groups. 


******************************2018 thoughts*********************************

Jan 2 2018:

1. Start writing. Try to set up the introduction and related work. 
2. Finish data analysis pipeline. and ANOVA tests between different groups. Do within group analysis. ?? Kruskal


Jan 3 2018:

1. Start implementing simulation pipeline for mico. 
	1. Write data into matlab files using sio? Easier for analysis. 
	2. Implement NumHessian and NumJacobian. Or use numdifftools and quantify the differences between MATLAB and python. 
	3. Start setting up code for mico simulation. Look at the potential field testing setup. Think about data collection. 
	4. Implement Bayesian. In the intent inference node. Set up service to alter. 
	5. Code to compute best mode using ENT, FI, DISAMB. Can modify the disamb_algo node to take a flag and trigger the appropriate function. 
	6. Timer to keep track of number of control steps that has passed. 
	BASICALLY PORT EVERYTHING FROM MATLAB TO PYTHON. 



2. a. Should I have a flag which will determine what features should DFT, CONF and BAYES be paying attention to? Need a lot more samples 	for enough samples per condition combination. 
   b. Check Bayesian implementation. How could it be made better. Refer to literature for other implementation. How is this different from POMDP based updates. How to incorporate history. 
   c. Check MATLAB code for any other errors and possible modifications. 


Other ideas:

1. Capturing human dynamics(?) using Koopman or LSTM systems? 
2. Mode scheduling? Can this be used to "solve" for the optimal way to solve a task given the dynamics (human) and the constraints (mode constraints). 
3. Keep track of the histogram of control commands issued. Use that to determine the p(uh) when computing the integral over the control subspaces. This can be done only when using the real robot in simulation or hardware. Should this happen in a separate node. 

Other notes:

1. Symbolic differentiation is almost going to be thrown out of the window for anything beyond a simple heuristic based intent inference scheme. 
2. The result is SUPER sensitive to minor changes in the position. This is not a great feature. It should be robust. 



READING:

1. Read the references from Miller's paper. Understand thoroughly if the reappropriation of parameter estimation techniques using Fisher Information applicable to mode switching domain. 



******************************************************************
******************************************************************
******************************************************************
******************************************************************


PAPER STRUCTURE FOR RSS 2018:

What is the paper about?

Intent disammbiguation in information theoretic terms:
Proposes two different algorithms for intent disambiguation: entropy-based, Fisher information based
Extensive simulation based investigation of various components that affects intent disambiguation
Proof-of-concept implementation on a simulation of the robotic arm to show that the system works for real robots as well. 

This paper introduces two different information theoretic measures for intent disambiguation for an assistive robotic arm. Entropy and Fisher Information based metrics are used to characterize the disambiguation capabilities of a control mode. 

purpose of simulation study:
We perform a thorough evaluation of the various components that affects the shared control system. We wnate to investiagte how well the system is able to infer intent, how operating in the disambiguation mode helps in activating assistance "earlier" and more accurately during task execution. 

Total time taken would be reduced as a result of faster assistance?


ABSTRACT:
Assistive machines 
Appropriate assistance can be provided only when intent inference is accurate. The benefit of assistance is maximized if the assistance can be provided earlier during task execution. Important to elicit intent clarifying control commands from the user. T Our previous exploratory studies indicated that the success of the disambiguation system depends on a variety of factors and choice of parameters. In order to thorooughly investigate the impact of these choice, we present a simulation results both for point-robots that live in different worlds as well on the simulated robotic arm. We present results 

INTRODUCTION:
Shared control robotic systems benefit from more accurate intent inference. A scheme for intent disambiguation is therefore useful. We propose two different schemes of control mode selection to maximize intent disambiguation grounded in information theoretic principles.  The first approach compares the entropy of the projected prbability distribution along different modes. The second approach relies on the Fisher information of the entropy of the goal distribution. The latter approach relies on the senstivity of entropy changes to motions in different control modes. We present experimental evaliuation in which investiagte the impact of different components of a shared control system (choice of intent inference mechanism, choice of disambiguation, task relevant features that contribute to inference). 
Compares how early assistance kicks in, how long does the assistance stay active duing the course of task execution. 

RELATED WORK:

SHARED CONTROL
NEED FOR INFERENCE.
MODE SWITCHING SCHEMES

INTENT CLARIFICATION
ENTROPY, KL DIVERGENCE AS INFORMATION GAIN

INTENT INFERENCE SCHEMES. 

MATHEMATICAL FORMALISM:
	CHARACTERIZATION OF CONTROL MODES AS SUBSETS OF CONTROL SPACES.
		FORMALLY USING SET-THEORETIC IDEAS. 
	MODE SELECTION SCHEMES:
	MAXIMAL REMAINING POTENTIAL: %FOR TRANSLATIONAL, BASED ON HOW MUCH MORE TO GO/ORIGINAL DISTANCE ALONG EACH DIMENSION. METRIC IS UNITLESS. 
		BASELINE
	DISAMBIGUATION SCHEMES
		ENTROPY BASED DISAMBIGUATION - 
		FISHER INFORMATION BASED DISAMBIGUATION
		HEURISTIC BASED DISAMBIGUATION (CITE PREVIOUS WORK)
	INTENT INFERENCE MECHANISMS
		DFT-BASED INTENT INFERENCE SCHEME (MATH BASED...) 
		BAYESIAN INFERENCE SCHEMES (MATH BASED...)
		HEURISTIC METHODS. CONFIDENCE FUNCTION

	SHARED CONTROL SCHEME: One column description. 

EXPERIMENTAL EVALUATION:
	DIFFERENT SIMULATION ENVIRONMENTS.
		1. R2 
		2. SE2
		3. R3
		4. SE3
	Common features: Random number of goals and goal positions. Random robot position. Autonomy based on potential field in the corresponding space. Simulated human followes a strategy which goes directly towrads the goal in the current mode. 

	DEMONSTRATION on REAL SYSTEM. 
	Mode switching schemes are activated every n time steps. 
	Baseline mode switching scheme is based on maximal remaining fractional potential in each control mode. 
	Entropy based disambiguation
	Fisher Info based disambiguation
	Heuristic based disambiguation


	NULL HYPOTHESIS:

	H0: There is no difference in when the assistance gets triggered for various conditions
	H0: There is no difference between the fractional percentage time for which assistance is active. 



	For the disambiguation schemes, the "assistance " towards the CORRECT goal gets triggered EARLIER than pure maximal fractional potential scheme. 
	For disambiguation schemes, the total time for which the assistance is present is greater. 
	Disambiguation schemes are more useful in the earlier parts of the trial. Once the intent becomes clear, opting for a fractikonal potential approach might get you more gains. 






MICO SIMULATION NOTES:

1. Setup the packages. Implement Bayes in the intent inferenc enode. Implement confidence function.
 2. Set up packages which can spawn random goals, spawn the necessary potential fields, random robot position (get the robot to that start position)

5. Code to compute best mode using ENT, FI, DISAMB. Can modify the disamb_algo node to take a flag and trigger the appropriate function. 
	6. Timer to keep track of number of control steps that has passed. 


	******

	In Todd's paper the  unknown variable which is the position of the object is TRULY unknown. AND it is a parameter which affects the measurement distribution. 

	Measurement variable which is a Gaussian random variable is a function of the unknown parameter/variable!! There is a separate probability distribution for the unknown parameter that is being maintained and updated via Bayes rule. The position of the sensor 'x' is being treated as a fixed parameter in the computation of the Fisher information. 



	What is pitch reagrding why we [perform] complex robot simulations!

	Initial thought: To show that EVEN on a real robot the same kinds of results hold. Why is th


	How about we replicate the expeirment study. 

	2-3 different goal scenes. 
	2-3 different home positions

	With and without refers to using POT or KL. Standard ways of switching. Every 5 or 8 seconds. Use the data. and perform same kind of analyse For how many users?

	Maybe. Can I do this by hand? possibly?

	Need to create a fake joy stick node which would publish uh





	Discussion:

	Improve model of uh. Relaxed assumption. Sparsity, maginutude variations, suboptimal policies. 
	Improve the nonlinearity function
	Learn kinematic model of the robot from data. DNN, Koopman apporaches for more accurate forward projections. 
	Simulations results indicate that this could possibly help people.Validate in real study
	Second order information. Fisher information. Active Learning. 
	 

	Here is what I thought of:


	I think that just showing that the algorithm works on a real robot simulation is trivial and comparison between real robot in SE(3) and point-robot in SE(3) is missing the point. 
	If we want to look into the utility value and power of disambiguation, we have to be able to compare the performance when disambiguation is active to a scenario when it is not. 

	Rather than following the same protocol we have for the MATLAB simulation which involves spawning new goal configurations for every and evaluating different mode switch assistance schemes on them, how about we try to simulate a real human study. The rationale is this will be time efficient, cost efficient and provides a good sneak peek into how useful it might be for a real human subject. 

	In order to do that, just like how we do it for our studies, we will predefine the tasks, maybe a simple reaching and a complex reaching task. We will have 3-4 home positions defined. Just like how I had a trial script for the actual study, I will have a trial script for this study as well which will specify, the home position, starting mode, mode switch type (KL or baseline), which is human's intended goal etc. 

	We will have autonomy and blending running for every trial. 

	The key difference is going to be this. W

	e will have a simulated human. For our MATLAb simulations, u_h was generated using a very simple rule in which the user tried to go to the intended goal in the straightest possible path, conditioned on the current control mode at maximum speed. We can relax that assumption to capture variations in users. We can have some randomness added to the direction and magnitude and can make the signal sparser. The parameters that control the randomness will be different for different simulated humans, thereby capturing variations such as aggressiveness/timidity and continuous/intermittent that are present in different individuals. 

	When it comes to mode switching, in a real human study, the user gets to switch whenever s/he wants. But in this case, we will have the mode switch algorithm triggered at regular intervals, say every 5 seconds. We will have a timeout of maybe 40-45 seconds for task completion. And we can repeat it. We will have two mode switch types: baseline (which is equivalent to the user not using the disambiguation algorithm) and disambiguation. For a trial marked 'baseline', only the baseline mode switch scheme will be utilized and similarly for disambiguation. 

	I am hoping that I will be able to write a bash script that can run the "study" launch files and at the end of the trial, kill them all and put them all in a loop. 

	By doing this, we can posibly shed some light on how useful disambiguation switching schemes would be for predicting intent earlier, accurately and confidently in a real scenario with real humans. 



