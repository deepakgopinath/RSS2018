\documentclass[conference]{IEEEtran}
\usepackage{times}
% numbers option provides compact numerical references in the text. 
\usepackage[numbers]{natbib}
\usepackage{multicol}
\usepackage{tabularx}
\usepackage[bookmarks=true]{hyperref}
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{graphicx}
\usepackage[numbers]{natbib}
\usepackage{multicol}
\usepackage[bookmarks=true]{hyperref}
\usepackage{amsmath,amssymb,latexsym,float,epsfig,subfigure}
\usepackage{amsmath} % assumes amsmath package installed  % assumes amsmath package installed
\usepackage{mathtools, bbm}
\usepackage{lipsum}
\usepackage[export]{adjustbox}
\usepackage[normalem]{ulem} % underline
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{balance}
\usepackage{color}
\usepackage{url}
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{algorithm, algorithmic}
\DeclareMathOperator*{\argmax}{argmax}
%\newcommand{\argmax}{\arg\!\max}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\pdfinfo{
	/Author (Deepak Gopinath, Brenna D. Argall)
	/Title  (Mode Switch Assistance to Human Intent Disambiguation)
	/CreationDate (January 31 2017)
	/Subject (Robots)
	/Keywords (Robots)
}
% numbers option provides compact numerical references in the text. 


\pdfinfo{
   /Author (Homer Simpson)
   /Title  (Robots: Our new overlords)
   /CreationDate (D:20101201120000)
   /Subject (Robots)
   /Keywords (Robots;Overlords)
}

\begin{document}

% paper title
\title{Information Theoretic Formulation of Intent Disambiguation}
\author{Author Names Omitted for Anonymous Review. Paper-ID [\textbf{163}]}
% You will get a Paper-ID when submitting a pdf file to the conference system
%\author{Deepak Gopinath and Brenna D. Argall}

%\author{\authorblockN{Deepak Gopinath}
%\authorblockA{Department of Mechanical\\Engineering,
%Northwestern University\\
%Evanston, Illinois 30332\\
%Email: deepakedakkattilgopinath2015\\@u.northwestern.edu}
%\and
%\authorblockN{Brenna D. Argall}
%\authorblockA{Department of Mechanical\\Engineering,
%		Northwestern University\\
%		Evanston, Illinois 30332\\
%		Email: brenna.argall@northwestern.edu}
%	}

%\author{Deepak Gopinath$^{1}$ and Brenna D. Argall$^{2}$
%	\thanks{Manuscript received: March, 1, 2016; Revised June,
%		7, 2016; Accepted June, 29, 2016.}
%}
% avoiding spaces at the end of the author lines is not a problem with
% conference papers because we don't use \thanks or \IEEEmembership


% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\authorblockN{Deepak E. Gopinath\authorrefmark{1}\authorrefmark{2},
%		Brenna D. Argall\authorrefmark{1}\authorrefmark{2}\authorrefmark{3}\authorrefmark{4}
%	}
%	\authorblockA{
%		\authorrefmark{1}Department of Mechanical Engineering, Northwestern University, Evanston, IL}
%	
%	\authorblockA{\authorrefmark{2}Rehabilitation Institute of Chicago, Chicago, IL}
%	
%	\authorblockA{\authorrefmark{3}Department of Physical Medicine and Rehabilitation, Northwestern University, Chicago, IL}
%	
%	\authorblockA{\authorrefmark{4}Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL}
%	
%	\authorblockA{{\tt\small deepakgopinath@u.northwestern.edu}}
%	\authorblockA{{\tt\small brenna.argall@northwestern.edu}}
%}

\maketitle

\begin{abstract}
In this paper, we formulate the problem of intent disambiguation in information theoretic terms.  We propose two different control mode selection schemes for intent disambiguation using information theoretic ideas of \textit{entropy} and \textit{Kullback-Leibler Divergence} for an assistive robotic manipulator. The effectiveness of assistive robots is closely related to their ability to infer the users' needs and intentions and provide appropriate types of assistance quickly and accurately. The proposed algorithms characterize the disambiguation capabilities of different control modes by the forward projection of probability distributions over goals and computing the average information gain and content. Our previous exploratory pilot studies revealed that the success of the disambiguation system depends on a variety of factors and choice of parameters. In order to thoroughly investigate the impact of various components, we present results from an extensive simulation-based study both for point-robots that reside in different spaces as well as on the simulation of a real robotic arm. Our results indicate that with the disambiguation algorithm the robot is able to assist earlier during task execution. Furthermore, the goal inferences are more accurate and the total amount of assistance greater when operating in the disambiguating modes compared to the baseline. 
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}
Assistive shared-control machines such as robotic arms, smart wheelchairs  and myoelectric prosthesis have the potential to transform the lives of millions of people with motor impairments as a result injuries to the central nervous system~\citep{laplante1992assistive}. These machines can promote independence, enhance the quality of lives and revolutionize the way they interact with society. They can also help to extend the mobility and manipulation capabilities of individuals thereby helping motor-impaired people perform activities of daily living in a more effective manner. 

An assistive robotic machine is typically controlled using control interfaces such as joysticks, switch-based head arrays and sip-and-puffs. These interfaces are low-dimensional, low-bandwidth and occasionally discrete, and can operate only in subsets of the entire control space. These subsets are referred to as \textit{control modes}. The efficacy of assistive machines rely on their ability to infer the users' needs and intentions and is often a bottleneck for providing appropriate assistance quickly, confidently and accurately. Due to the dimensionality mismatch between the high-dimensional robots and the low-dimensional interfaces, the users are constrained to produce control commands that likely does not reveal the true intent in an unambiguous and expressive manner. That is, the control interfaces act like filters that restrict the amount of information regarding intent that gets passed through. 
%Furthermore, sparsity and noise in the control commands make the inference process even harder prompting the need for robust intent inference formalisms. 

In the context of assistive robotic manipulation, often the first step of a task is to reach for and grasp discrete objects in the environment. Therefore, intent inference can be cast as a problem of maintaining the probability distribution over all possible discrete goals (objects) in the workspace. Intent inference mechanisms typically rely on various environmental cues and task-relevant features such as robot and goal positions, human control commands and biometric measures for estimating the most probable goal. However, due to cost considerations and user acceptance issues, our system tries to infer intent primarily based on the information contained in the constrained control commands issued to the assistive machine.

Our insight is that the information contained in control commands issued in certain control modes will clarify human's underlying intent unambiguously and is likely to be more useful for the robot to perform accurate intent inference. This, in turn will help the robot to appropriate kinds of assistance more effectively. In this paper, we formulate the problem of intent disambiguation in information-theoretic terms. More specifically, we rely on information theoretic notions of \textit{entropy} and \textit{Kullback-Leibler Divergence} to characterize and quantify the intent disambiguation capabilities of a control mode. We utilize this characterization of control modes to develop a mode switch assistance paradigm that enhances the robot's intent inference capabilities, by selecting the control mode in which a user-initiated motion will \textit{maximally disambiguate} human intent. 
%The disambiguation system will likely elicit more \textit{intent expressive} commands from the user by placing the user control in certain control modes.


In Section~\ref{sec:related_work} we present an overview of relevant research in the areas of shared autonomy in assistive robotics, types of shared autonomy assistance paradigms and use of information theoretic tools in information acquisition. Section~\ref{sec:math} presents the set theoretic treatment of control modes mathematical formalism for the intent disambiguation and intent inference. Section~\ref{sec:shared-control} focuses on the implementation details of the shared control system. The study design and experimental methods are discussed in Section~\ref{sec:ed} followed by results in Section~\ref{sec:results}. Discussion and conclusions are presented in Sections~\ref{sec:discussions} and~\ref{sec:conclusions} respectively. 


\section{Related Work}\label{sec:related_work}
This section presents an overview of related works in the areas of shared autonomy in assistive robotics, robot assistance for modal control, intent inference in human-robot interaction and information acquisition in robotics. 

Shared-autonomy in assistive machines aims to reduce the human's physical and cognitive burden during task execution without having the user completely cede manual control~\citep{philips2007adaptive, demeester2008user}. Some of the common shared-autonomy approaches include (a) hierarchical paradigms in which the higher level goals are entrusted with the user and the autonomy generates low-level control~\citep{kim2012autonomy}, (b) control allocation in distinct partitions of the control space~\citep{driessen2005collaborative} and (c) blending user controls and robot autonomy commands~\citep{muelling2017autonomy}. 

Due to the limitations of the control interfaces, users typically have to shift their focus from the task at hand to switching between various control modes during task execution and results in a higher cognitive load. Various mode switching assistance paradigms have been proposed to alleviate task effort. For example, a time-optimal mode switch assistance~\citep{herlant2016assistive} and heuristic based mode switch assistance to maximize intent disambiguation~\citep{gopinath2017mode}. 

For an assistive machine to provide appropriate kinds of assistance accurately and at the right time, it needs to have a good estimate of the human's underlying intent. Intent inference algorithms, therefore, play a vital role in the success of a shared-control assistive system. Intent inference and recognition can be classified into two broad categories: heuristic approaches and model-based approaches. Heuristic approaches are often simpler and computationally light-weight and seek to find direct mappings between various task relevant features such as motion cues and the human's underlying intention~\citep{baker2007goal, baker2009action}. On the other hand, in model-based approaches, the human is modeled within the Partially Observable Markov Decision Process (MDP)~\citep{taha2011pomdp, dragan2013policy} framework and is assumed to behave according to a control policy that maps states to actions. However, in Bayesian schemes, incorporating the entire history of states requires estimation of joint probability distributions that can become quickly intractable. 

Robot assistance schemes that seeks to elicit more informative cues from the human to clarify the underlying intent can be thought of as an information acquisition problem. Intent acquisition can leverage the underlying synergies and shared intentionality~\citep{tomasello2007shared} of human-robot teams and can be an active process in which the robot performs actions (for example, selecting a control mode or executing a robot motion) that will nudge the human to reveal her/his intent more clearly~\cite{sadigh2016information, sadigh2016planning}. More generally, in the field of machine learning and experimental design, active learning is widely used for improving the efficiency of estimating unknown model parameters from data. Data collection is time consuming and expensive; therefore, it is necessary to obtain data samples that contain the greatest amount of information regarding the unknown parameters. In parameter estimation problems, researchers usually start with a prior distribution on the parameters which then gets updated upon the arrival of new data samples. Information theoretic metrics such as a KL-divergence can be utilized to identify regions of the sample space that will maximize information gain~\citep{tong2001active} and subsequently guide the data sampling process. 
Sensing robots designed for automated exploration and data acquisition tasks can benefit from exploring more information-rich regions in the environment~\citep{atanasov2014information}. If the spatial distribution of information density is known \textit{a priori}, information maximization can be accomplished by maximizing the ergodicity of the robot's trajectory with respect to the underlying information density map~\citep{miller2016ergodic, miller2013trajectory}. 

\section{Mathematical Formalism}\label{sec:math}
This section describes the mathematical details of the intent disambiguation algorithm that computes a control mode that can maximally disambiguate between the various goals. Section~\ref{ssec:notation} outlines the mathematical notation used in this paper. Section~\ref{ssec:set_modes} presents a set-theoretic treatment of control modes and Section ~\ref{ssec:disamb} describes the disambiguation algorithm. The mathematical details of the intent inference paradigms are outlined in detail in Section~\ref{ssec:inference}.
\subsection{Notation}\label{ssec:notation}
 In assistive robotic manipulation, as the robot is mainly used for reaching toward and grasping of discrete objects in the environment, intent inference is process of estimating the user's intended goal. The set of all candidate goals is denoted by $\mathcal{G}$ with $n_g = \vert\mathcal{G}\vert$ and let $g^i$ refer to the $i^{th}$ goal with $i \in [1,2,\dots, n_g]$. At any time $t$, the unknown goal $g$ follows a categorical probability distribution whose sample space is $\mathcal{G}$. 
 That is, 
 \begin{equation*}
 g \sim \textbf{Cat}(n_g | \boldsymbol{p}(t)) = \prod_{i=1}^{n_g}p^{i}(t)^{[g = g^i]}
 \end{equation*}
where, $[g = g^i]$ is the Iverson bracket and evaluates to 1 if $g = g^i$, 0 otherwise. $\boldsymbol{p}(t)$ denotes the probability distribution over goals such that $\boldsymbol{p}(t) = [p^1(t), p^2(t),\dots, p^{n_g}(t)]^{T}$ where $p^i(t)$ denotes the probability associated with goal $g^i$.  The probability $p^i(t)$ represent the robot's \textit{confidence} that goal $g^i$ is the human's intended goal. 

Let $\mathcal{K}$ be the set of all controllable dimensions of the robot and $k^i$ represent the $i^{th}$ control dimension where $i \in [1,2,\dots,n_k]$ with $n_k = \vert\mathcal{K}\vert$. The number of controllable dimensions ($n_k$) depends on the robotic platform used. Let $\boldsymbol{x_r}$ denote the position of the robot's end-effector position with respect to the world frame. The mathematical space in which $\boldsymbol{x_r}$ resides and the number of controllable dimensions depends on the robotic platform. For example, a 2D point robot that operates has $\boldsymbol{x_r} \in \mathbb{R}^2$, whereas a 6DOF robotic manipulator has $\boldsymbol{x_r} \in \mathbb{SE}(3)$. Lastly, let $\boldsymbol{u_h} \in \mathbb{R}^{n_k}$ denotes the human control command issued via the control interface and $\boldsymbol{u_r} \in \mathbb{R}^{n_k}$ denote the robot autonomy command\footnote{For the rotational control dimensions, the velocity is specified with respect to the end-effector of the robotic frame.}. 

\subsection{Set Theoretic Treatment of Control Modes}\label{ssec:set_modes}
%
%The limitations of the control interfaces necessitate the control space $\mathcal{K}$ to be partitioned into control modes. Let $\mathcal{M}$ denote the set of all control modes with $n_m = \vert\mathcal{M}\vert$. Additionally, let $m^i$ refer to the $i^{th}$ control mode where $i \in [1,2,\dots,n_m]$. Each control mode $m^i$ is a subset of $\mathcal{K}$ such that $\bigcup\limits_{i=1}^{n_m} m^i$ spans all of the controllable dimensions.\footnote{Note that a dimension $k \in \mathcal{K}$ can be an element of multiple control modes.} Let $\boldsymbol{e}^i$ be the standard basis vectors that denote the unit velocity vector along the $i^{th}$ control dimension.\footnote{For the rotational control dimensions, the velocity is specified with respect to the end-effector of the robotic frame.} Furthermore, the user can only operate in one of the $n_m$ control modes at any given time $t$. Therefore, the user can only access smaller subsets of $\mathbb{R}^{n_k}$ via the control interface with $\mathcal{U}_{m^i}$ denoting the subset of $\mathbb{R}^{n_k}$ accessible from control mode $m^i$. Figure 1 represents this in a pictorial fashion for a robot residing in $\mathbb{R}^2$. 

The low dimensionality of the control interfaces necessitates the control space $\mathcal{K}$ to be partitioned into control modes. Let $\mathcal{M}$ denote the set of all control modes with $n_m = \vert\mathcal{M}\vert$. Additionally, let $m^i$ refer to the $i^{th}$ control mode where $i \in [1,2,\dots,n_m]$. Each control mode $m^i$ is a subset of $\mathcal{K}$ such that $\bigcup\limits_{i=1}^{n_m} m^i$ spans all of the controllable dimensions. The cardinality of each mode denoted by $\vert m \vert$ indicates the number of dimensions that can be controlled when operating in $m$.\footnote{Note that a dimension $k \in \mathcal{K}$ can be an element of multiple control modes.} Furthermore, the user can only operate in one of the $n_m$ control modes at any given time $t$. That is, for each $m \in \mathcal{M}$, the subspace of $\mathcal{R}^{n_k}$ that is accessible corresponds to $\mathcal{R}^{\vert m \vert}$ whose basis vectors are given by $\boldsymbol{e}^k \;\; \forall \;\; k \in m$. Maximum velocity limits along each dimension imposes further constraints on the set of control commands that are available in each mode. The set of control commands denoted by $\mathcal{U}^m$, can be written as 
\begin{equation*}
\mathcal{U}^m = \{\boldsymbol{u} \in \mathcal{R}^{\vert m \vert}, s.t \norm{\boldsymbol{u}}_{\infty} \leq c \} 
\end{equation*}
where $c$ denotes the maximum velocity along any dimension $k$ and $\norm{\cdot}_{\infty}$ denotes the $L_\infty$ norm. Therefore, the set $\mathcal{U}^m$ corresponds to a hypercube of dimensionality $\vert m \vert$ embedded in $\mathcal{R}^{n_k}$. In other words $\mathcal{U}^m$ is a $\vert m \vert$-cube with edge length equals $2c$. Without loss of generality, the velocity limits can be different for different control dimensions in which case $\mathcal{U}^m$ will correspond to a hypercuboid. Figure 1 represents this in a pictorial fashion for a robot residing in $\mathbb{R}^2$. 
 \begin{figure}[h]
	\centering
	\includegraphics[width= 0.8\hsize, height=0.2\vsize]{./figures/R2_ControlModes.eps}
	\vspace{-0.35cm}
	\caption{Illustration of 1D and 2D control modes in a two-dimensional control space, $\mathbb{R}^2$. Note that this space can be embedded in a higher dimensional space such as $\mathbb{R}^3$, $\mathbb{SE}(2)$ and $\mathbb{SE}(3)$. The 1D control modes are shown in blue and orange and the 2D control mode is shown as the green shaded area within the red square. The vertex set denotes the maximum magnitude control commands that can be issued when operating in a control mode. }
	\label{fig:r2_modes}
\end{figure}

% The disambiguation formalism developed in Section~\ref{ssec:disamb} is agnostic to the particular form of intent inference. However, the algorithm assumes that $\boldsymbol{p}(t)$ can be forward projected in time by iteratively applying the intent inference algorithm. 
\subsection{Disambiguation Schemes}\label{ssec:disamb}

The need for intent disambiguation arises from the manner in which the probability distribution over goals evolves as the user controls the robot and performs the task. The evolution of the probability distribution is closely related to the choice of intent inference mechanism as well as the features that contribute to it. If the evolution is sensitive to the user control command, then it is likely that the goal probabilities evolve in different ways as the user operates the robot in different control modes. Our aim is to develop a metric that will estimate the ``disambiguation capability'' of control dimension/mode. The hypothesis is that subsequent user operation of the robot in the control mode with maximum disambiguation capability will ``help'' the robot to perform better intent inference and likely will result in providing appropriate kinds of assistance. 

The first step towards the computation of the disambiguation metric $D_m$ is the forward projection of the probability distribution $\boldsymbol{p}(t)$ from current time $t_a$ to $t_b$ such that $t_a < t_b$. The exact computation of the projected probability distribution will depend on the underlying intent inference computation---for example, whether it depends on $\boldsymbol{x_r}$ (which can be computed from $\boldsymbol{u}_h$ applied to the robot kinematics model) or $\boldsymbol{u}_h$. All parameters and features which affect the computation of $\boldsymbol{p}(t)$ are denoted as $\boldsymbol{\Theta}$. If the inference mechanism depend on the control command, the projected probability distribution at time $t_b$ given by $\boldsymbol{p}(t_b)$ depends on $\boldsymbol{u_h}$. For the purposes of computation of the disambiguation metric, in each mode $m \in \mathcal{M}$, we only consider the set containing the ``vertices'' of the $\vert m \vert$-cube, denoted by $Vert(\mathcal{U}^m)$. The probabilities are forward projected for each of the possible control commands available in $Vert(\mathcal{U}^m)$ (Algorithm~\ref{alg:disamb}, Lines 5-9) and a weighted average of all disambiguation metric computations on each of the projected probabilities is used to characterize the control mode $m$. In the following sub-sections we present two different methods to compute the disambiguation metric for a given mode $m$. 

 \begin{figure}[h]
	\centering
	\includegraphics[width= 1.\hsize, height=0.3\vsize]{./figures/Disamb_Compute.eps}
	\vspace{-0.35cm}
	\caption{Illustration of computation of $D_m$ in $\mathbb{R}^2$. The goals are shown in red, green and blue and the robot is depicted in black. The probability distributions are forward projected for all $\boldsymbol{u_h} \in Vert(\mathcal{U}^m)$. The change in the overall shape of the probability distribution upon evolving from $\boldsymbol{p}(t_a)$ to $\boldsymbol{p}(t_b)$ amounts to the information `gain' and is captured by the \textit{KL-Divergence}. The entropy of $\boldsymbol{p}(t_b)$ captures the information `content' present in the distribution.} 
	\label{fig:disamb_compute}
\end{figure}


\subsubsection{Entropy Based Disambiguation Metric}\label{sssec:ent}
The entropy of the probability distribution is reflective of the average information content of a stochastic source of data. For a discrete random variable $X$ with possible values $\{x_1, x_2,\dots x_n\}$, the Shannon entropy is defined as 

\begin{equation*}
ENT(P(X)) = -\sum_{i = 1}^{n} P(x_i)log_{2}P(x_i)
\end{equation*}
where $P(X)$ denotes the probability mass function.

Lower entropy indicates higher certainty in the value of the random variable and vice-versa. Therefore, entropy of the projected probability distribution, $\boldsymbol{p}(t_b)$, can be used as a measure of how confident the system is in its prediction of human intent. That is, entropy can be used a measure of disambiguation. Lower the entropy better the disambiguation due to higher certainty in the human's intended goal. The disambiguation capability of a control mode $m$ is characterized by computing a weighted average of the entropies of projected probability distributions for all possible control commands $\boldsymbol{u_h} \in Vert(\mathcal{U}^m)$. That is
\begin{equation}
D_m = \frac{1}{\vert Vert(\mathcal{U}^m) \vert}\sum_{\boldsymbol{u_h} \in Vert(\mathcal{U}^m)}  ENT(\boldsymbol{p}(t_b; \boldsymbol{u_h}))
\end{equation}
where $\boldsymbol{p}(t_b; \boldsymbol{u_h})$ denotes the projected probability distribution at time $t_b$ when the control command used for forward projection is $\boldsymbol{u_h}$.
\subsubsection{KL-Divergence Based Metric}\label{sssec:kl}
KL-Divergence, also known relative entropy, measures how one probability distribution differ from another distribution. KL-Divergence is widely used in the context of Bayesian inference to compute the information gain when the prior is updated to the posterior in the light of new evidence. For a discrete random variable $X$ with possible values $\{x_1, x_2,\dots x_n\}$ the KL-Divergence is defined by
\begin{equation*}
KL(P||Q) = -\sum_{i=1}^{n}P(x_i)log_2\frac{Q(x_i)}{P(x_i)}
\end{equation*}
where $P(X)$ and $Q(X)$ are two different probability mass distributions. 
In the context of disambiguation we can treat the projected probability distribution as the posterior and distribution at time $t_a$ to be the prior. KL-Divergence can then be used to characterize the information gain regarding the human's intended goal as a result of the application of $\boldsymbol{u_h}$. More specifically, the disambiguation capability of control mode $m$ is computed by averaging the information gain for all possible control commands $\boldsymbol{u_h} \in Vert(\mathcal{U}^m)$. That is the disambiguation metric can be computed as 
\begin{equation*}
D_m = \frac{1}{\vert Vert(\mathcal{U}^m) \vert}\sum_{\boldsymbol{u_h} \in Vert(\mathcal{U}^m)} KL(\boldsymbol{p}(t_b; \boldsymbol{u_h})||\boldsymbol{p}(t_a))~~~~.
\end{equation*}
\begin{algorithm}[t]
	\caption{Calculate $\boldsymbol{p}(t_b)$, $D_m$}
	\label{alg:disamb}
	\begin{algorithmic}[1]
		\REQUIRE $\boldsymbol{p}(t_a), \boldsymbol{x}_r(t_a), \Delta t, t_a < t_b, \boldsymbol{\Theta}$
		\FOR{$m=1\dots n_m$}
		\STATE Initialize $D_m = 0$
		
		\FOR{$\boldsymbol{u_h} \in Vert(\mathcal{U}^m)$}
		\STATE Initialize $t = t_a, \boldsymbol{x_r}(t) = \boldsymbol{x_r}(t_a), \boldsymbol{p}(t) = \boldsymbol{p}(t_a)$
		\WHILE{$t \leq t_b$}
		\STATE $\boldsymbol{p}(t + \Delta t) \leftarrow \text{UpdateIntent}(\boldsymbol{p}(t), \boldsymbol{u}_h; \boldsymbol{\Theta})$
		\STATE $\boldsymbol{x}_r(t + \Delta t) \leftarrow \text{SimulateKinematics}(\boldsymbol{x}_r(t), \boldsymbol{u}_h)$
		\STATE $t \leftarrow t + \Delta t$
		\ENDWHILE
		
		\STATE $D_m \leftarrow D_m + \frac{1}{\vert Vert(\mathcal{U}^m) \vert} ENT(\boldsymbol{p}(t_b)) $
		
		or
		
		\STATE $D_m \leftarrow D_m + \frac{1}{\vert Vert(\mathcal{U}^m) \vert} KL(\boldsymbol{p}(t_b) \vert\vert \boldsymbol{p}(t_a)) $
		
		\ENDFOR
		\ENDFOR
	\end{algorithmic}
\end{algorithm}
The control mode with highest disambiguation capability $m^*$ is given by $\argmax_m D_m$. Disambiguation mode $m^*$ is the control mode that system chooses \textit{for} the human to better estimate their intent. Any control command issued by the human when operating in $m^*$ is likely to be more beneficial for the robot to determine the human's intended goal. 

\subsection{Intent inference}\label{ssec:inference}
This section describes the different types of intent inference schemes used in this paper. Our preliminary pilot studies indicated that the disambiguation power of our algorithm is closely linked to the inference power of different choices of inference mechanisms. 
%This is because, during the forward projection step, different intent update schemes result in different projections and affects the computation of the disambiguation metric. 

\subsubsection{Heuristic Approaches}
Heuristic approaches based on \textit{confidence} functions seek to find direct mappings between instantaneous cues and underlying human intentions. For every goal $g \in \mathcal{G}$, the system maintains an associated set of confidences denoted by $\mathcal{C}$. The system designer has the freedom to choose the set of features that will inform the confidences. For example, a simple proximity-based confidence function used extensively in literature is
\begin{equation}
c(\boldsymbol{x_r}, \boldsymbol{x_g}) = max\Big(0, 1 - \frac{\norm{\boldsymbol{x_r} - \boldsymbol{x_g}}}{r}\Big)
\end{equation}
where $\boldsymbol{x_r}$ is the robot position, $\boldsymbol{x_g}$ is the goal position, $r$ is the radius beyond which the confidence function is always 0 and $\norm{\cdot}$ is an appropriate distance metric. 
%A confidence function that relies purely on proximity features, however, ignores all information regarding human intent contained in the control command itself. 
A slightly more information-rich variant that aims to capture the ``directedness'' of the human control command to a particular goal position is
\begin{equation*}
c({\boldsymbol{x_r},\boldsymbol{x_g}, \boldsymbol{u}_{h}}) = \boldsymbol{u}_h\cdot(\boldsymbol{x}_{g} - \boldsymbol{x_r})
\end{equation*}
where $\boldsymbol{u_h}$ is the human control command. 

The drawback of heuristic approaches is that information contained in the history of states is typically ignored. As a result, the inference is not robust to external noise and can exhibit chatter behavior. 
\subsubsection{Bayesian Approaches}
Bayesian approaches to intent inference consists of iterative updating of the belief (probability distribution over goals) as new evidence arrives at every time-step. The Bayesian update equation for the probability distribution over goals is given by
\begin{equation*}
\underbrace{p(g_t| \boldsymbol{u}^{1:t}_{\boldsymbol{h}}, \boldsymbol{\Theta})}_{posterior} = \eta \underbrace{p(\boldsymbol{u}^{1:t}_{\boldsymbol{h}} | g_t, \boldsymbol{\Theta})}_{likelihood}\underbrace{p(g_{t-1})}_{prior}
\end{equation*}
where $\eta$ is the normalization factor, $\boldsymbol{u}^{1:t}_{\boldsymbol{h}}$ is the entire history of control commands and $\boldsymbol{\Theta}$ denoted all other task-relevant and environment features that informs the inference process. Under first-order Markovian assumption the equation can be simplified by only considering the control command at the current time step $t$. The likelihood function captures how the human teleoperates the robot in order to accomplish a goal and can be either learned from data, or be hand-designed based on certain heuristics. Incorporating past history of states becomes cumbersome in Bayesian schemes as estimating the joint likelihood of control commands becomes intractable. 
\subsubsection{Dynamic Neural Field Based Approaches}
In this approach, the individual goal probabilities are treated as constrained dynamical state variables whose time evolution is determined by a dynamic neural field such that $p^i(t) \in [0, 1]$ and $\Sigma_{1}^{n_g}p^{i}(t) = 1$~\citep{gopinath2017disamb}. Recurrent interaction between the state variables, robustness to external noise and inherent memory make dynamic neural fields an ideal candidate for an intent inference engine. Historically, dynamic neural fields were conceived to explain cortical population neuronal dynamics, based on the hypothesis that the excitatory and inhibitory neural interactions between local neuronal pools form the basis of cortical information processing~\citep{schoner1995dynamics, schoner2008dynamical}. 

 The dynamical system that governs the time evolution of goal probabilities can be generically written as 
\begin{equation*}
\dot{\boldsymbol{p}}(t) = F(\boldsymbol{p}(t), \boldsymbol{u}_h ; \boldsymbol{\Theta})
\end{equation*}
where $F$ represents the nonlinear vector field, $\boldsymbol{u}_h$ is the human control input and $\boldsymbol{\Theta}$ represents all other task-relevant features and parameters that affect the time-evolution of the probability distribution. 
The full specification of the neural field is given by
\begin{multline}\label{eq:dft}
\frac{\partial \boldsymbol{p}(t)}{\partial t} = \frac{1}{\tau}\bigg[-\mathbb{I}_{n_g\times n_g}\cdot\boldsymbol{p}(t) + \underbrace{\frac{1}{n_g}\cdot\mathbbm{1}_{n_g}\bigg]}_{\text{rest state}} + \\ \underbrace{\boldsymbol{\lambda}_{n_g\times n_g}\cdot\sigma(\boldsymbol{\xi}(\boldsymbol{u}_h;\boldsymbol{\Theta}))}_{\text{excitatory + inhibitory}}
\end{multline}
where time-scale parameter $\tau$ determines the memory capacity of the system, $\mathbb{I}_{n_g\times n_g}$ is the identity matrix, $\mathbbm{1}_{n_g}$ is a vector containing all ones of dimension $n_g \times 1$, $\boldsymbol{\lambda}$ is the control matrix that controls the excitatory and inhibitory aspects, $\boldsymbol{\xi}$ is a function that encodes the nonlinearity through which human control commands and task features affect the time evolution, and $\sigma$ is a biased sigmoidal nonlinearity given by $\sigma(\boldsymbol{\xi}) = \frac{1}{1 + e^{-\boldsymbol{\xi}}} - 0.5$. 
%In the absence of any information or cues, the probability distribution settles to a resting state which is a uniform distribution, that is whenever $\boldsymbol{u}_h = 0$, $\boldsymbol{\xi} = \vec{0}$. 
Given the initial probability distribution at time $t_a$ Equation~\ref{eq:dft} can be solved numerically from $t \in [t_a, t_b]$ using a simple Euler algorithm with a fixed time-step $\Delta t$. The design of $\boldsymbol{\xi}$ is informed by what features of the human control input and environment capture the human's underlying intent most effectively. We rely on the \textit{directedness} of the human control commands towards a goal, the \textit{proximity} to a goal and the \textit{agreement} between the human commands and robot autonomy.

\section{Shared Control}\label{sec:shared-control}
In our system, control sharing is achieved with a blending-based paradigm in which the final control command issued to the robot is a weighted linear combination of the user control command and robot autonomy. 
\subsection{Blending Paradigm}\label{ssec:blending}
The autonomous control policy generates control command
$\boldsymbol{u}_r \leftarrow f_{r}(\boldsymbol{x})$
where $f_{r}(\cdot) \in \mathcal{F}_{r}$, and $\mathcal{F}_{r}$ is the set of all control behaviors corresponding to different tasks. 
Specifically, let $\boldsymbol{u}_{r,g}$ be the autonomy command associated with goal $g$. The final control command $\boldsymbol{u}$ issued to the robot then is given by
\begin{equation*}
\boldsymbol{u} = \alpha\cdot \boldsymbol{u}_{r,g^*} + (1 - \alpha)\cdot \boldsymbol{u}_h
\end{equation*}
where $g^*$ is the most confident goal and corresponds to the mode of $\boldsymbol{p}(t)$. The blending parameter, $\alpha$ is a piecewise linear function of the $p(g^*)$ and is specified as
$$
\alpha = \left\{
\begin{array}{ll}
0 & \quad\quad~~~ p(g^*) \leq \rho_1 \\
\frac{\rho_3}{\rho_2 - \rho_1}\cdot p(g^*) &  \quad \text{if}\quad \rho_1 < p(g^*) \leq \rho_2  \\
\rho_3 & \quad\quad~~~ p(g^*) > \rho_2 	
\end{array}
\right.
$$
with $\rho_i \in [0, 1] \;\forall\; i \in [1,2,3]$ and $ \rho_2 > \rho_1$. 
In our implementation, we empirically set $\rho_1 = \frac{1.2}{n_g}, \rho_2 = \frac{1.4}{n_g}$ and $ \rho_3 = 0.7$.

The robot control command $\boldsymbol{u}_{r,g}$ is generated using a simple potential field which is defined in all parts of the state space~\citep{khatib1986real}. Every goal $g$ is associated with a potential field $\gamma_g$ which treats $g$ as an attractor and all the other goals in the scene as repellers.
\begin{equation*}
\dot{\boldsymbol{x}}_r^{attract} = \boldsymbol{x}_{g} - \boldsymbol{x_r}
\end{equation*}
where $\boldsymbol{x}_{g}$ is the location of goal $g$. Each dimension of $\dot{\boldsymbol{x}}_r^{attract}$ can be interpreted as the magnitude of the attractive \textit{pull} towards the goal along that dimension. 
The repeller velocity is given by
\begin{equation*}
\dot{\boldsymbol{x}}_r^{repel} = \sum_{i \in \mathcal{G} \setminus g} \frac{\boldsymbol{x_r} - \boldsymbol{x}_{g^i}}{\mu(\norm{\boldsymbol{x_r} - \boldsymbol{x}_{g^i}}^2)}
\end{equation*}
where $\dot{\boldsymbol{x}}_r$ indicates the velocity of the robot in the world frame, $\mu$ controls the magnitude of the repeller velocity. The autonomy command is computed as a summation of these attractor and repeller velocities.
\begin{equation*}
\boldsymbol{u}_{r,g} = \dot{\boldsymbol{x}}_r^{attract} + \dot{\boldsymbol{x}}_r^{repel} 
\end{equation*}
$\gamma_g$ operates in the full six dimensional Cartesian space, and treats position and orientation as independent potential fields. 

\subsection{Maximum Potential Mode Switch Assistance}\label{ssec:maxpot}
As a baseline for the simulation experiments described in Section~\ref{sec:ed} we also propose a simple greedy mode switch assistance scheme. At any given time $t$, the system selects the control mode which has the \textit{maximum attractive pull} towards the goal. For each control dimension $k$, the magnitude of the $k^{th}$ dimension of $\dot{\boldsymbol{x}}_r^{attract}$ is a measure of the attractive pull along $k$. Each control mode $m \in \mathcal{M}$ is summarized by the total attractive potential of all control dimensions $k$ such that $k \in m$.
\section{Experimental Evaluation}\label{sec:ed}
In this section we describe simulation experiments conducted on point-like robots and the simulated robot environment to evaluate the effectiveness of our disambiguation algorithm.
\subsection{Point Robot Simulation Setup}
\subsubsection{Robot Workspace}
Our simulations were performed on point-like robots that reside in $\mathbb{R}^2$, $\mathbb{R}^3$, $\mathbb{SE}(2)$ and $\mathbb{SE}(3)$ spaces. The translational workspace limits were set at $[-0.4m, 0.4m]$ along each translational dimension and the orientation limits were set at $[0, 2\pi]$ along each rotational axis. Table~\ref{tbl:manip} lists all the factors there were randomized and manipulated for each trial. 
\begin{table}[t]
	\centering
	\begin{tabular}{|p{3cm}|p{3cm}|}
		\hline
		\textbf{Variable} &\textbf{Range}  \\ \hline
		$n_g$ &  $[2,6]$ \\ \hline
		$\mathcal{M}$ & Randomly selected from Table~\ref{tbl:cmp} conditioned on the space\\ \hline
		Intent Inference & ['Conf', 'Bayes', 'DFT] \\ \hline
		Initial Robot Position & Randomized within workspace limits \\ \hline
		Goal Positions & Randomized within workspace limits \\ \hline
		Intended Goal & Randomly chosen from $\mathcal{G}$ \\ \hline
	\end{tabular}
	\vspace{.2cm}
	\caption{Randomized Factors for Each Simulation Trial} 
	\label{tbl:manip}
	\vspace{-.5cm}
\end{table}

\subsubsection{Mode Switch Schemes}
Four different mode switching schemes were activated during each simulation trial, three of which performed intent disambiguation and one which served as a baseline for comparison. The disambiguation algorithms were entropy-based (Section~\ref{sssec:ent}), KL-Divergence based (Section~\ref{sssec:kl}) and a heuristic-based approach which was developed in an earlier work~\citep{gopinath2017mode}. We used the mode switching scheme described in Section~\ref{ssec:maxpot} as the baseline for comparison. 
\subsubsection{Simulated $\boldsymbol{u_r}$ and $\boldsymbol{u_h}$}
The simulated robot autonomy $\boldsymbol{u^{sim}_r}$ is generated using a repeller-free potential field. In a given control mode $m \in \mathcal{M}$, the simulated human control command denoted by $\boldsymbol{u^{sim}_h}$ is given by
\begin{equation*}
\boldsymbol{u^{sim}_h} = \argmax_{\boldsymbol{u_h} \in Vert(\mathcal{U}^m)} \boldsymbol{u_h}\cdot(\boldsymbol{x_g}^{intended} - \boldsymbol{x_r})
\end{equation*}
where $\boldsymbol{x_g}^{intended}$ is the position of the human's intended goal which is known only to the human and the system tries to infer using the inference scheme. This model of simulated human control command assumes that the user issues control commands at all times and always tries to optimize for distance and time. The final control command issued to the point robot was determined by the blending-based shared control scheme described in Section~\ref{sec:shared-control}.
\subsubsection{Metrics}
The following metrics were used to evaluate the efficacy of the disambiguation algorithm compared to the baseline mode switch assistance:
\begin{itemize}
%	\item \textit{Task Completion Time (s)}: The amount of time for a successful trial to reach the goal. 
%	\item \textit{Number of Mode Switches}: This metric refers to the number of times the control mode switch from the current mode to a different mode. 
	\item \textit{Initial Onset of Assistance (s)}: Earliest time at which assistance towards the intended goal was triggered. This measure captures how \textit{quickly} the robot was able to infer the correct goal  \textit{and} provide assistance. 
	\item \textit{Total Amount of Assistance (\%)}: Fraction of the total trial time for which assistance towards the intended goal was present.  
	\item \textit{Inference Accuracy (\%)}: Fraction of the total trial time for which the intent inference mechanism correctly inferred the human's intended goal. This is a measure of overall confidence of the system. 
\end{itemize}

\subsubsection{Simulation Protocol}
5000 simulation runs were performed for each of the scenarios. 
The maximum trial duration was set at $12s$ or equivalently $120$ time-steps with $\Delta t = 0.1$. The mode switch assistance algorithm was activated once every $4$ time-steps. The trial was ended prematurely if the robot reached within the intended goal as determined by a pre-specified distance threshold. 
 \begin{figure}[h!]
	\centering
	\includegraphics[width= 0.8\hsize, height=0.26\vsize]{./figures/WS_SIM.eps}
	\vspace{-0.35cm}
	\caption{Example of point-like robot simulation in $\mathbb{R}^2$. The goals are represented in black, the initial robot position in red and the human's intended goal in magenta. The different colored trajectories correspond to different mode switching schemes. Potential-based (Black), Entropy-based (Red), KL Divergence-based (Blue) and Heuristic-based (Green).} 
	\label{fig:ws_sim}
\end{figure}
 \begin{figure}[t!]
	\centering
	\includegraphics[width= 1.\hsize, height=0.45\vsize]{./figures/initial_alpha.eps}
	\vspace{-0.75cm}
	\caption{Group differences for initial onset of assistance for different simulation scenarios. Box plots show the median and the quartiles.} 
	\label{fig:initial_alpha}
\end{figure}

\begin{table}[t]
	\centering
	\begin{tabular}{|p{1cm}|p{0.5cm}|p{3cm}|}
		\hline
		\textbf{Space} & $n_k$ &\textbf{Control Mode Sets}  \\ \hline
		$\mathbb{R}^2$ & $2$ & $\{[1],[2]\}$ \\ \hline
		$\mathbb{R}^3$ & $3$ & $\{[1],[2]\}$, $\{[1,2], [3]\}$ \\ \hline
		$\mathbb{SE}(2)$ & $3$ &  $\{[1],[2],[3]\}$, $\{[1,2], [3]\}$ \\ \hline
		$\mathbb{SE}(3)$ & $6$ & $\{[1],[2],[3],[4],[5],[6]\}$, $\{[1,2,3],  [4,5,6]\}$, $\{[1,2], [1,3], [4,5], [6]\}$, $\{[1,2], [1,3], [4,5], [6]\}$ \\ \hline
	\end{tabular}
	\vspace{.2cm}
	\caption{Predefined control space partition sets for each of the simulation spaces.} 
	\label{tbl:cmp}
	\vspace{-.5cm}
\end{table}

\subsection{MICO Robot Simulation Setup}
We also evaluated our system in a real robot simulation environment (MICO robotic arm from Kinova Robotics). The end effector of the robot lives in $\mathbb{SE}(3)$; however, the physical constraints of the robot make the kinematics highly nonlinear compared to that of a point robot in $\mathbb{SE}(3)$. We evaluated the system on two tasks: 1) Four goals with same orientation and 2) five goals with different orientations. Two mode switching schemes were tested: KL-divergence based disambiguation and the maximum potential based mode switching. For every trial, the robot autonomy was generated using a potential field as described in Section~\ref{ssec:blending}. 
However, unlike the point robot simulation in $\mathbb{SE}(3)$, the simulated human control command was made more realistic by adding noise to the magnitude and direction of the signal. 

\section{Results}\label{sec:results}

In this section we present the results from the simulation studies conducted on point-like robots in different spaces. One way analysis of variance was performed using Kruskal-Wallis test and post-hoc analysis between groups was conducted using a multiple comparison test that used Tukey's HSD criterion. All analysis was performed in MATLAB. In all the data plots, (*) indicates $p < 0.05$, (**) indicates $p < 0.01$ and (***) indicates $p < 0.001$.
\subsection{Initial Onset of Assistance}

Kruskal-Wallis test reveals that the group ranks are different for all simulation scenarios. Post-hoc analysis also reveals statistically significant differences between the baseline mode switch assistance scheme and at least one disambiguation scheme for all simulation scenarios (Figure~\ref{fig:initial_alpha}). This shows that when the disambiguation scheme is used, the system is able to provide assistance \textit{quicker} and \textit{earlier} during task execution.

\subsection{Amount of Total Assistance}
%\vspace*{-0.7cm}
\begin{figure}[t]
	\centering
	\includegraphics[width= 1.\hsize, height=0.6\vsize]{./figures/total_assistance.eps}
	\vspace{-0.8cm}
	\caption{Group differences for total amount of assistance for different simulation scenarios. Box plots show the median and the quartiles.} 
	\label{fig:total_assistance}
\end{figure}
For all simulation scenarios, Figure~\ref{fig:total_assistance} shows a statistically significant increase in the total amount of assistance when disambiguation schemes are active compared to the baseline. This is possibly because disambiguation modes help to \textit{reveal} the intent more clearly \textit{to} the robot. As a result the overall confidence in the system's prediction of intended goal increases, thereby resulting in more assistance. 
%\subsection{Number of Mode Switches}
%\begin{figure}[h]
%	\centering
%	\includegraphics[width= 1.\hsize, height=0.53\vsize]{./figures/num_mode.eps}
%	\vspace{-0.35cm}
%	\caption{Group differences for total amount of assistance for different simulation scenarios. Box plots show the median and the quartiles.} 
%	\label{fig:num_mode}
%\end{figure}
%The results in Figure~\ref{fig:num_mode} shows that the number of mode switches is significantly lower for the disambiguation paradigms. Furthermore, for all simulation scenarios except $\mathbb{R}^2$, using KL-divergence based disambiguation resulted in the lowest number of mode switches. 

\subsection{Inference Accuracy}
\begin{figure}[t!]
	\centering
	\includegraphics[width= 1.\hsize, height=0.35\vsize]{./figures/correct_inference.eps}
	\vspace{-0.75cm}
	\caption{Group differences for fractional time for correct goal inference for different simulation scenarios. Box plots show the median and the quartiles.} 
	\label{fig:correct_inference}
\end{figure}
As shown in Figure~\ref{fig:correct_inference}, for all simulation scenarios, except $\mathbb{SE}(2)$, the accuracy of intent inference was higher for the disambiguation schemes compared to the baseline. This is likely because of the fact that, disambiguating modes elicit control commands that carry more information regarding the intended goal thereby helping the system to perform accurate intent inference. 
\section{Discussion}\label{sec:discussions}
\section{Conclusion}\label{sec:conclusions}


\section*{Acknowledgments}
Funding source omitted for review. 
%% Use plainnat to work nicely with natbib. 
\balance
\bibliographystyle{plainnat}
\bibliography{references}

\end{document}


